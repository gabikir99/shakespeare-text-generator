{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83525f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b394cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-8) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(preds), p=preds)\n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, n_words=25, temperature=1.0):\n",
    "    result = []\n",
    "    input_text = seed_text\n",
    "\n",
    "    for _ in range(n_words):\n",
    "        encoded = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        encoded = encoded[-seq_len:]\n",
    "        padded = np.pad(encoded, (seq_len - len(encoded), 0), mode='constant')\n",
    "        padded = padded.reshape(1, -1)\n",
    "\n",
    "        preds = model.predict(padded, verbose=0)[0]\n",
    "        pred_id = sample(preds, temperature)\n",
    "\n",
    "        next_word = tokenizer.index_word.get(pred_id, \"<UNK>\")\n",
    "        result.append(next_word)\n",
    "        input_text += ' ' + next_word\n",
    "\n",
    "    return ' '.join([seed_text] + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a49330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "lstm_model = load_model(\"best_model_lstm.h5\")\n",
    "gru_model = load_model(\"best_model_gru.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56949eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Output:\n",
      "to be or not to give it stir with paid hither both nay he in grace as up us yet keep they'll be not the faith i can ha sight\n",
      "\n",
      "GRU Output:\n",
      "to be or not to not with nay good lands and i will never say not on a enemy of them not with very humphrey with your of they empress\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"to be or not to\"\n",
    "seq_len = 50\n",
    "\n",
    "print(\"LSTM Output:\")\n",
    "print(generate_text(lstm_model, tokenizer, seq_len=50, seed_text=\"to be or not to\", n_words=25, temperature=0.8))\n",
    "\n",
    "\n",
    "print(\"\\nGRU Output:\")\n",
    "print(generate_text(gru_model, tokenizer, seq_len=50, seed_text=\"to be or not to\", n_words=25, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35f2f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original text (used during training)\n",
    "with open(\"alllines.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Convert to tokens\n",
    "tokens = tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73dd881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_seed_text(tokenizer, tokens, seq_len=50):\n",
    "    start_idx = random.randint(0, len(tokens) - seq_len - 1)\n",
    "    seed_ids = tokens[start_idx : start_idx + seq_len]\n",
    "    seed_words = [tokenizer.index_word.get(i, \"<UNK>\") for i in seed_ids]\n",
    "    return ' '.join(seed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70c56a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:\n",
      "do mock thee thus stamp rave and fret that i may sing and dance thou wouldst be fee'd i see to make me sport york cannot speak unless he wear a crown a crown for york and lords bow low to him hold you his hands whilst i do set\n",
      "\n",
      "LSTM Output:\n",
      "do mock thee thus stamp rave and fret that i may sing and dance thou wouldst be fee'd i see to make me sport york cannot speak unless he wear a crown a crown for york and lords bow low to him hold you his hands whilst i do set so bashful what song down thus from thy lusts lies bring her marry and they base it eyes in you i'll succession in grossly as\n",
      "\n",
      "GRU Output:\n",
      "do mock thee thus stamp rave and fret that i may sing and dance thou wouldst be fee'd i see to make me sport york cannot speak unless he wear a crown a crown for york and lords bow low to him hold you his hands whilst i do set dismiss him memory here cheer make away the third as the warlike despair oil and her poor fight my other ranks comforted to france tis\n"
     ]
    }
   ],
   "source": [
    "seed_text = get_random_seed_text(tokenizer, tokens, seq_len=50)\n",
    "\n",
    "print(\"Random Seed:\")\n",
    "print(seed_text)\n",
    "\n",
    "print(\"\\nLSTM Output:\")\n",
    "print(generate_text(lstm_model, tokenizer, seq_len=50, seed_text=seed_text, n_words=25, temperature=1.0))\n",
    "\n",
    "print(\"\\nGRU Output:\")\n",
    "print(generate_text(gru_model, tokenizer, seq_len=50, seed_text=seed_text, n_words=25, temperature=1.0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
